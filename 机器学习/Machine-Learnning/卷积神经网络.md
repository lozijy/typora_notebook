# 卷积神经网络

全连接神经网络处理大尺度图形具有三个明显的缺点

1将图形展开成向量会丢失信息

2参数过多效率低

3参数过多过拟合

卷积神经网络中的神经元是三维排列的:快读，高度，深度

深度是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度是网络的层数

一个小例子:

   

卷积层是构建卷积神经网络的核心层，产生了网络中大部分的



卷积的作用:

1.卷积层的参数一些可学习的滤波器集合构成的。每个滤波器在宽度和高度比较小，但是深度和输入数据一致。

网络会让滤波器在它看到某些类型的视觉特征时就激活，具体的视觉特征可能是颜色的斑点，方位上的边界等等

2.可以看做是神经元的一个输出



感受野:每个神经元只与输入数据的一个局部区域连接，连接的空间大小叫神经元的感受野，它的尺寸是一个超参数，在深度方向上，这个连接的大小总是和输入量的深度相等。连接在空间上是局部的，在深度上和输入数据的深度一致



。

假设输入数据体尺寸[32*32*5]感受野大小是5*5

那么卷积层中的每个神经元会有5\*5*3个权重

卷积层的空间排列



上面感受野讨论了卷积层中每个神经元和输入数据体之间的连接方式，但没讨论输出数据体的神经元数目。三个超参数控制输出数据体的尺寸，深度,步长，零填充

1.深度:和滤波器数目一致，而每个滤波器在输入数据中找一些一些不同的东西，即图像的某些特征

2.步长，滑动的时候要指定步长，步长为1，则滤波器每次移动1个像素，步长是2，滤波器就每次移动2个像素

3.零填充



输出数据体尺寸和输入数据体尺寸,感受野尺寸，步长，滤波器竖向，和零填充的关系:

权值共享



卷积层:

卷积 归一化 磁化

