### 进行 T-Test

------

进行一个 t-test, 看离职员工的满意度是不是和未离职员工的满意度明显不同

[14]

```
import scipy.stats as stats
# 满意度的t-Test
stats.ttest_1samp(a = df[df['turnover']==1]['satisfaction'], # 离职员工的满意度样本
                  popmean = emp_population)  # 未离职员工的满意度均值
```

Ttest_1sampResult(statistic=-51.33034867547431, pvalue=0.0)

T-Test 显示pvalue **(0)** 非常小, 所以他们之间是显著不同的





1.

t检验是用t分布理论来推论差异发生的概率，从而比较两个平均数的差异是否显著。它与f检验、卡方检验并列。

t检验的来历

当总体呈正态分布，如果总体标准差未知，而且样本容量<30，那么这时一切可能的样本平均数与总体平均数的离差统计量呈t分布。

检验是用 分布理论来推论差异发生的概率，从而比较两个平均数的差异是否显著。 检验分为单总体检验和双总体 检验。

1.单总体t检验

单总体 检验是检验一个样本平均数与一已知的总体平均数的差异是否显著。当总体分布是正态分布，如总体标准差未知且样本容量 <30，那么样本平均数与总体平均数的离差统计量呈 分布。

2.双总体t检验

双总体 检验是检验两个样本平均数与其各自所代表的总体的差异是否显著。双总体 检验又分为两种情况，一是相关样本平均数差异的显著性检验，用于检验匹配而成的两组被试获得的数据或同组被试在不同条件下所获得的数据的差异性，这两种情况组成的样本即为相关样本。二是独立样本平均数的显著性检验。各实验处理组之间毫无相关存在，即为独立样本。该检验用于检验两组非相关样本被试所获得的数据的差异性。

1.2 用处
单样本检验：检验一个正态分布的总体的均值是否在满足零假设的值之内。

双样本检验：其零假设为两个正态分布的总体的均值是相同的。这一检验通常被称为学生t检验。但更为严格地说，只有两个总体的方差是相等的情况下，才称为学生t检验；否则，有时被称为Welch检验。以上谈到的检验一般被称作“未配对”或“独立样本”t检验，我们特别是在两个被检验的样本没有重叠部分时用到这种检验方式。

检验同一统计量的两次测量值之间的差异是否为零。举例来说，我们测量一位病人接受治疗前和治疗后的肿瘤尺寸大小。如果治疗是有效的，我们可以推定多数病人接受治疗后，肿瘤尺寸变小了。这种检验一般被称作“配对”或者“重复测量”t检验。

检验一条回归线的斜率是否显著不为零。


2.

T检验，亦称student t检验（Student's t test），主要用于样本含量较小（例如n<30），总体标准差σ未知的正态分布资料。

T检验是用于小样本（样本容量小于30）的两个平均值差异程度的检验方法。它是用T分布理论来推断差异发生的概率，从而判定两个平均数的差异是否显著。

p-value是一种概率：在原假设为真的前提下，出现该样本或比该样本更极端的结果的概率之和



![image-20221114151901440](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114151901440.png)

![image-20221114151909793](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114151909793.png)

![image-20221114151923961](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114151923961.png)





### 获取训练集和测试集

```python
# 将string类型转换为整数类型
df["department"] = df["department"].astype('category').cat.codes
df["salary"] = df["salary"].astype('category').cat.codes

# 产生X, y，即特征值与目标值
target_name = 'turnover'
X = df.drop('turnover', axis=1)
y = df[target_name]

# 将数据分为训练和测试数据集
# 注意参数 stratify = y 意味着在产生训练和测试数据中, 离职的员工的百分比等于原来总的数据中的离职的员工的百分比
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.15, random_state=123, stratify=y)
# 显示前5行数据
df.head()
```

### 开始训练

```python
from sklearn import tree
import pydotplus 
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz

from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
```



```python
# 实例化
dtree = tree.DecisionTreeClassifier(
    criterion='entropy',
    #max_depth=3, # 定义树的深度, 可以用来防止过拟合
    min_weight_fraction_leaf=0.01 # 定义叶子节点最少需要包含多少个样本(使用百分比表达), 防止过拟合
    )
# 训练
dtree = dtree.fit(X_train,y_train)
# 指标计算
dt_roc_auc = roc_auc_score(y_test, dtree.predict(X_test))
print ("决策树 AUC = %2.2f" % dt_roc_auc)
print(classification_report(y_test, dtree.predict(X_test)))
```

roc_auc_score

![image-20221114152937925](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114152937925.png)







关于roc:

![image-20221114153203210](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153203210.png)



![image-20221114153226064](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153226064.png)





![image-20221114153356796](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153356796.png)

roc_auc_score函数返回曲线下面积，输入和roc_curve函数一样。



### 可视化

```python
# 需安装GraphViz和pydotplus进行决策树的可视化
# 特征向量
feature_names = df.columns[1:]
# 文件缓存
dot_data = StringIO()
# 将决策树导入到dot中
export_graphviz(dtree, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_names,class_names=['0','1'])
# 将生成的dot文件生成graph
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
# 将结果存入到png文件中
graph.write_png('diabetes.png')
# 显示
Image(graph.create_png())
```

![image-20221114153606148](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153606148.png)

### 决策树的特征重要性分析

```python
# 获取特征重要性
importances = dtree.feature_importances_
# 获取特征名称
feat_names = df.drop(['turnover'],axis=1).columns
# 排序
indices = np.argsort(importances)[::-1]
# 绘图
plt.figure(figsize=(12,6))
plt.title("Feature importances by Decision Tree")
plt.bar(range(len(indices)), importances[indices], color='lightblue',  align="center")
plt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')
plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)
plt.xlim([-1, len(indices)])
plt.show()
```

![image-20221114153654862](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153654862.png)

### ROC曲线

![image-20221114153803827](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153803827.png)

![image-20221114153815792](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221114153815792.png)