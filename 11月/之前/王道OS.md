内存管理

内存抽象:

指令

heap

free

stack

寄存器:

进程调度

中断，系统调用

### cpu和处理器的关系

cpu就是处理器

### 什么是多核，什么是多处理器

核(core)是cpu最重要的部分，cpu中间突出的芯片就是核，由硅制作

cpu，处理器

### 

### 计算机系统的体系结构

单处理器

多处理器

- 多核：性能优于多个单核处理器，因为多个处理器会发生竞争等问题

集群lan，web

### 寄存器分类

分类

通用寄存器:

专用寄存器: 指令寄存器，地址寄存器:防止进程在内存中的地址 数据寄存器,

内存:

外存:

作业池



### 操作系统的结构

内核

### 操作系统的运行机制

两种运行状态，核心态，用户态。两种运行指令，特权指令，非特权指令。两种程序，内核程序，应用程序

### 进程切换时cpu内部

寄存器保存当前运行状态，并退出运行 状态

### 中断，系统调用，异常

操作系统运行状态分为核心态和用户态，指令分为核心指令和用户指令.程序的调用和切换是通过中断完成的，进程运行结束/时间片用完/请求io操作/出现异常时，中断机制发生。操作系统由用户态切换为核心态，操作系统内核对中断发生的原因进行检查，检查完毕后重新切换会用户态

执行完每个指令后，操作系统都要检查当前是否有外部中断信号

### 一个典型的指令执行周期

cpu在内存中获取指令，存放在指令寄存器中，随后要么被解码，要么继续将内存中的数据存放在数据寄存器中

### 存储结构

CACHE 读取速度最快

RAM 读取速度中等

磁盘 读取速度最慢

cpu寄存器

内存

外存

### 计算机系统的体系结构

单处理器系统

多处理器系统

集群系统

### 操作系统结构

结构:单作业操作系统

多道批操作系统

分时系统

### 内存抽象

在真实内存中，用物理地址区分不同数据的位置，内存抽象后会将内存划分为很多个内存块.

每个代码块是这样的



stack和heap共享free的内容

内存中的地址分为 相对地址和真实地址,物理地址=相对地址+起始地址。

physical address=virtual address+base address

cpu中有基址寄存器和界限寄存器，在作业进入内存前，会自动加上基址寄存器的内容。

cpu中拥有内存管理单元MMU,专门用来对内存地址进行翻译

### 内存划分方式

单一连续存储管理

分区式存储管理

1. 固定分区
2. 动态分区

伙伴系统



# 第一章

###  中断和异常

1.作用

发生中断意味着操作系统介入，开展管理工作

**CPU收到计时部件发出的中断信号，切换为核心态对中断进行处理，控制权限给到操作系统，时间片用完了，给到进程2，控制权限给到用户程序，进程2发出系统调用(内中断信号)，此时控制权限又给到操作系统，操作系统进行I/O操作**

中断可以使操作系统从用户态转为核心态，使操作系统获得计算机控制权

用户态进入到核心态只能通过中断，**核心态进入用户态只需要把程序状态字PSW的标志位设置为用户态**

2.分类(广义)

**1.内中断 CPU内部**  

自愿中断-指令中断 系统调用时的访管指令(陷入指令，trap指令,汇编int)

强迫中断- 硬件故障 缺页 软件故障 除0

**2.外中断  CPU外部**

外设请求   I/O操作完成

人工干预	

另一种分类

1.内中断

陷阱，陷入(trap)

故障

终止

2.外中断

I/O中断

人工干预



3.外中断处理过程

一执行程序的一系列指令，每次执行完一个指令后就会检查是否有外部中断信号

**二如果检测到外部中断信号就会保护被中断进程的CPU环境(程序状态字PSW,程序计数器PC，通用寄存器)**

三**根据中断信号类型转入相应的中断处理程序(核心态)**

四恢复原进程的CPU环境并退出中断



### 系统调用

1.作用

提供给编程人员的接口函数。用户进程想使用共享资源，只能通过系统调用向操作系统发出请求，操作系统会对请求进行协调管理，保证系统的稳定性和安全性

2.分类

设备管理

文件管理

进程管理

进程通信

内存管理

2.系统调用和库函数的区别

普通应用程序其实可以直接使用汇编语言调用系统调用，但是一般的程序员都是通过库函数调用系统调用，部分库函数对系统调用进行了封装

3.系统调用的背后

高级语言中的某个函数被编译成汇编语言，汇编语言中回存在int陷入指令使操作系统进入核心态,int后面的参数指明了系统调用号

int 其实是执行陷入指令

陷入指令(int)是唯一一个只能在用户态执行，不能再核心态执行的指令

***系统调用涉及对系统资源的管理，对进程的控制，需要执行一些特权指令，因此需要在核心态下完成***

*凡是对资源进行操作的都需要通过系统调用执行，因此我们可以判断哪些操作是系统调用*

*系统调用发生在用户态，对系统调用的处理发生在核心态*

# 第二章 进程

### 进程

1.程序

程序:就是一个指令序列早期的计算机只支持单道

在内存中 内存包含了程序段和数据段，程序段放在低地址部分，数据段放在高地址部分

多道程序技术:多道程序并发进行,内存中存放着多个程序段和数据段

2.PCB和进程组成

为了方便管理，系统为每个运行的程序配置了一个数据结构pcb，用来描述进程的各种信息

PCB+数据段+程序段三部分组成了进程实体（简称进程），创建进程实际上就是创建PCB，撤销进程是撤销进程实体中的PCB

PCB是进程存在的唯一标志

3.进程定义(强调动态性)

进程是程序的一次执行过程

进程是一个程序及其数据在处理机上顺序执行时发生的活动

进程是具有独立功能的程序在数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位

引入进程实体后可把进行定义为:进程实体的运行过程，是系统进行资源分配和调度的一个独立单位

严格来说，进程实体和进程并不相同，进程实体是静态的，进程是动态的，不过除非题目专门考察二者区别，否则认为二者相同，可以说"进程实体是由PCB,程序段，数据段组成"

4.PCB组成

进程的管理者(os)所需的数据都在PCB中

PCB包括

1.进程描述信息

进程标识符PID,用户标识符UID

2.进程控制和管理信息

进程当前状态，进程优先级

3.资源分配清单

程序段指针，数据段指针，键盘，鼠标

4.处理机相关信息

各种寄存器的值

5.进程的组织

一个系统中通常有数十数百个PCB，应该用适当的方式把这些PCB组织起来

进程的组成讨论的是进程内部由哪些部分构成的问题，进程的组织讨论的是多个进程间组织方式问题

链接方式 

按照进程状态把PCB分为多个队列

操作系统持有只想各个队列的指针

执行指针

就绪队列指针

阻塞队列指针

索引方式

按照进程状态的不同建立几张索引表

操作系统持有只想各个索引表的指针

执行指针

就绪表指针

阻塞表指针

6.进程的特征

动态性 进程是程序的一次执行过程，是动态产生变化消亡的

并发性

独立性 独立运行，独立获得资源，独立接受调度的基本单位

异步性 各进程按各自独立的不可预知的速度向前推进，操作系统要提供进程同步机制来解决异步问题

结构性 每个操作系统都会配置一个PCB

### 进程的状态与转换

1.三种基本状态

运行态 :占有CPU并在CPU上运行

就绪态 :已经具备运行条件，但由于没有空闲CPU而暂时不能运行

阻塞态 :因等待某一事件二暂时不能运行，如等待操作系统分配打印机，等待读磁盘操作的结果

2.另外两种状态

创建态

操作系统需要完成创建进程，需要为该进程分配所需的内存空间等资源，并为其创建，初始化PCB(如分配PID)

终止态

进程运行结束(或因为BUG导致无法继续执行下去)，操作系统需要完成撤销进程相关工作，完成将分配给进程的资源回收，撤销进程PCB等工作

3.进程状态的转换

创建态-->就绪态

就绪态-->运行态

运行态-->就绪态

运行态-->阻塞态 进程用系统调用申请某种系统的资源，是进程的主动行为

阻塞态-->就绪态 不是系统自身能控制的，是一种被动行为



注意:不能由阻塞态直接转换为运行态，也不能由就绪态直接转换为阻塞态(因为就如阻塞态是进程主动要求的)

### 进程控制

1.什么是进程控制

对系统中的所有进程实施有效的管理，具有创建新进程，撤销已有进程，实现进程状态转换等功能

简单来说进程控制就是要实现进程状态转换

2.如何实现进程控制

原语实现进程控制，特点是执行期间不允许中断，一气呵成，这种不可中断操作就是原子操作

采用关中断和开中断指令实现

关中断指令--原语代码--开中断指令

关开中断的权限非常大，是只允许在核心态下执行的特权指令。

3.进程控制相关的原语

 更新PCB中的信息(修改进程状态标志，将运行环境保存在PCB，从PCB恢复运行状态)

将PCB插进合适的队列

分配回收资源

4.进程控制详细讲述

01.进程的创建

1.创建原语  创建态-->就绪态

​	申请空白PCB

​	为新进程分配所需的资源

​	初始化PCB

​	将PCB插入就绪队列

2.引起进程创建的条件

​	在分时系统中，用户登录成功，系统会为其建立一个新的进程

​	多道批处理系统中，有新的作业放入内存，会为其建立一个新的进程

​	用户向操作系统提出某些请求时，会新建一个进程处理该请求

​	由用户进程主动请求建立一个子进程

02.进程的终止

1.撤销原语  就绪态/阻塞态/运行态 -->终止态-->无

​	从PCB集合中找到终止进程的PCB

​	若进程正在运行，立即剥夺CPU，把CPU分配给其他进程

​	终止其所有子进程

​	将该进程拥有的所有资源归还给父进程或操作系统

​	删除PCB

2.引起进程终止的事件

​	正常结束

​	异常结束

​	外界干预



03.进程的阻塞

1.阻塞原语

​	找到套阻塞的进程对应的PCB

​	保护进程运行现场，把PCB状态信息设置为阻塞态，暂时停止进程运行

​	将PCB插入相应事件的等待队列

2.引起进程阻塞的条件

​	需要等待系统分配某种资源

​	需要等待相互合作的其他进程完成工作

04.进程的唤醒

1.唤醒原语

​	在对扩等待队列中找到PCB

​	把PCB从等待队列移除，设置进程为就绪态

​	将PCB插入就绪队列，等待被调度

2.引起进程唤醒的条件

​	等待的事件发生(因何事阻塞就应由何事唤醒)



05.进程的切换

1.切换原语

​	将运行环境信息存入PCB

​	PCB移入相应队列

​	选择另一个进程执行，并更新其PCB

​	根据PCB恢复新进程所需的运行环境

2.引起进程切换的事件

​	当前进程时间片到

​	有更高优先级的进程到达

​	当前进程主动阻塞

​	当前进程终止

### 进程通信

1.什么是进程通信 

进程通信就是指进程之间的信息交换，进程是分配系统资源的单位，因此各进程拥有的内存地址空间相互独立

为了保证安全，一个进程不能直接访问另一个进程的地址空间

但是进程之间的信息交换是必须实现的，为了保证进程间的安全通信，操作系统提供了一些方法

三大方式 共享存储，消息传递，管道通信

2.共享存储

操作系统为两个进程提供一个共享空间，两个进程对共享空间的访问必须是互斥的(通过操作系统提供的工具实现)

操作系统只负责提供共享空间和同步互斥工具(如P，V操作)

共享存储 :基于数据结构的共享，基于存储区的共享

基于数据结构的共享:比如共享空间里只能放一个长度为10的数组，这种共享方式速度慢，限制多，是一种低级通信方式

基于存储区的共享:在内存中画出一块共享存储区，数据的形式，存放位置由进程控制，而不是操作系统，这种共享方式速度更快，是一种高级通信方式

3.管道通信

管道是指用于连续读写进程的一个共享文件，又名pipe文件，其实就是在内存中开辟一个大小固定的缓冲区(linux中的pipe是4kb大小)，管道只能采用半双工通信，某一时间段只能实现单向的传输没如果要实现双向同时通信，则需要设置两个管道

各进程要互斥地访问管道。

进程1写数据必须把管道填满后进程2才能读取数据(read被消息交换阻塞)，同样，进程2读数据读完后进程1才能写数据(write被阻塞)

以字符流的形式写入管道

数据一旦被独处，就从管道中被抛弃，这意味着读进程只能有一个，否则会有读错数据的情况

4.消息传递

进程间的数据交换以格式化的消息为单位，进程通过操作系统提供的发送消息/接收消息两个原语进行数据交换。

消息包括消息头和消息体(和计算机网络中的TCP/IP报文有点像)

消息头包括:发送进程ID,接受进程ID，消息类型没消息长度等格式化的信息



消息传递包括了直接通信方式和间接通信方式

直接通信方式:消息直接挂到接受进程的消息缓冲队列上

间接通信方式:消息先发送到中间实体(信箱)中，因此也称信箱通信方式

### 线程概念和多线程模型

1.什么是线程，为什么要引入线程

传统进程只能串行的执行一系列程序，为此引入了线程，增加并发度

传统的进程是程序执行流的最小单位

引入线程后，线程成为了程序执行流的最小单位

每个进程拥有多个线程，每个线程拥有不同的代码或相同的代码

可以把线程当做轻量级进程

线程是一个基本的cpu执行单元

引入线程后不仅是进程间可以并发，进程内的各线程间也可以并发

引入线程后，进程只作为除CPU之外的系统资源的分配单元 (如打印机，内存地址空间)



2.引入线程机制后有什么变化?

资源分配，调度:

传统的进程是资源分配，调度的基本单位

引入线程机制后，进程是资源分配的基本单位，线程是调度的基本单位

并发性:

传统进程机制中，只能进程间并发

引入线程后，各进程间也能并发，提高了并发度

系统开销:

传统的进程间并发，需要切换进程的运行环境，系统开销很大

线程间并发，如果是同一进程内的线程切换，则不需要切换进程环境，系统开销小

引入线程后，并发带来的系统开销减小



3.线程的属性

各个线程都有一个线程ID，线程控制块(TCB)

也有就绪阻塞运行三种基本状态

线程几乎不用有系统资源

同一进程的不同线程间共享进程的资源(IO设备，内存空间)

由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预

同一进程中的线程切换，不会引起进程切换

不同进程中的线程切换，会引起进程切换

切换同进程内的线程，系统开销很小

切换不同进程内的线程，系统开销很大



4.线程的实现方式

分为用户级线程和内核级线程



用户级线程ULT

由应用程序通过线程库实现

所有的线程管理工作都有应用程序负责(包括线程切换)

用户级线程中，线程切换可以在用户态下即可完成，无需操作系统干预

在用户看来，是有多个线程，在操作系统内核看来意识不到线程的存在



内核级线程KLT

内核级线程的管理工作由操作系统内核完成。线程调度，切换由内核负责，因此必须在核心态下完成



在同时支持用户级和内核级线程的系统中，可采用二者组合的方式将n个用户级线程映射到m个内核级线程上



注意:操作系统只能看见内核级线程，所以只有内核级线程才是处理机分配的单位,比如在四核处理机上内核空间里有2个内核级线程，用户空间里有3个用户级线程，那么只能有2个核心被分配，也只能有2个线程并行执行



5.多线程模型

在同时支持用户级线程和内核级线程的系统中，由几个用户级线程映射到几个内核级线程的问题引出了多线程模型问题

多对一模型 ：多个用户级线程映射到一个内核级线程

优点:用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高

缺点:由于内核级线程才是处理机分配的单位，一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高，多个线程不可在多核处理机上并行运行



一对一模型：一个用户级线程映射到一个内核级线程

优点:并发能力强,一个线程被阻塞后，别的线程还可以继续执行

缺点:一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，线程管理的成本高，开销大



多对多模型:n个用户级线程映射到m个内核级线程

克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点



### 进程调度

处理机调度的概念，层次

高级调度(作业调度):按一定原则从外存上处于后备队列的作业中挑选一个或多个作业，给他们分配内存等必要资源并建立相应PCB

中级调度(内存调度):暂时调到外村等待的进程状态叫挂起状态，PCB并不会一起调到外村，而是会常驻内存,pcb会记录进程数据在外存中的存放位置，进程状态等信息，操作系统通过内存中的PCB来保存对各个进程的监控，管理。被挂起的PCB会被放到挂起队列中。中级调度决定将那个处于挂起状态的进程重新调入内存。

补充:进程的挂起态和七状态模型.

注意区别挂起态和阻塞态:二者都暂时不会获得处理机资源，但是挂起态的进程映像在外存中，阻塞态的进程映像在内存中，进程映像包括了进程的PCB,数据段和程序段

七状态模型:



低级调度(进程调度):按某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。进程调度室操作系统中最基本的一种调度，在一般的操作系统中都会配置进程调度。

进程调度的频率很高，一般几十毫秒一次



#### 进程调度的时机，切换与过程，方式

1.时机

需要进程调度:

进程主动放弃处理:进程正常重视，运行发生异常而终止

进程被迫放弃处理机:分给进程的时间片用完了，有更紧急的事需要处理(如I/O中断)，有更高优先级的进程进入就绪队列

不能进程调度:内核临界区的进程，处理中断的过程，在原子操作的过程中（原语）

区别:内核临界区和普通临界区

临界资源:一个时间段内值允许一个进程使用的资源，各进程需要互斥地访问临界资源

临界区：访问临界资源的代码

内核临界区:一般用来访问某种内核数据结构的(比如进程的就绪队列)，如果一个进程还没退出内核临界区就进行进程调度，那么此时就绪对扩是被锁住的，无法进行进程调度

普通临界区:如果一个进程访问的是一个普通的临界资源(比如打印机)，在打印机完成之前，进程一直处于临界区内，临界资源不会解锁，但打印机又是慢速设备，此时如果一直不允许进程调度的话会导致CPU一直闲置

2.进程调度的方式:

抢占式:系统可以强行使进程放弃处理机资源，如果时间片分完，或有更紧急的事，或有更高优先级的进程在就绪队列中时会剥夺该进程的处理机资源。

非抢占式:进程只能主动放弃处理机资源

分时操作系统都是抢占式的调度方式

3.切换与调度的区别:

狭义的进程调度室就绪队列选中一个要运行的进程。

进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。

进程切换主要完成了对原来进程各种数据的保存，对新的进程各种数据的恢复(如：程序计数器，程序状态字，各种数据寄存器等处理机现场信息，这种信息一般保存在进程控制块)

注意:进程切换是有代价的，因此如果过于频繁的进行进程调度，切换，必然会使整个系统的效率降低，使系统大部分时间花在进程切换上，而真正用于执行进程的时间减小。

#### 调度算法的评价指标

CPU利用率

系统吞吐量

周转时间 平均周转时间

带权周转时间 平均带权周转时间

等待时间:进程/作业等待被服务时间之和

响应时间:从用户提交请求到首次产生响应所用的时间

#### 调度算法

先来先服务FCFS

短作业优先SJF

高响应比优先HRRN

时间片轮转调度算法(RR)

优先级调度算法

多级反馈队列调度算法

### 进程同步 进程互斥



#### 进程互斥的软件实现

#### 进程互斥地硬件实现

### 信号量机制

### 死锁

## 第三章 内存管理

### 内存的基本知识

内存条的基本知识:内存是从放数据的设备，程序执行前需要先放到内存中才能被CPU处理。

多个程序并发执行，如何区分各个程序的数据放在什么地方的?内存中有一个一个的存储单元，内存地址从0开始每个地址对应一个存储单元。如果计算机按字节编址，则每个存储单元为1字节，如果字长为16位，则每个存储单元大小为1个字，字不一定是2个字节，需要看计算机的机器字长。

进程的运行原理:指令,每个进程由程序段，数据段，PCB组成，指令就存储在程序段中，指令一般用的是逻辑地址(相对地址)

源代码编译后生成一个个模块，再链接后生成装入模块(可执行文件)，再装入到内存。

装入的三种方式(三种不同的方法完成逻辑地址到物理地址的转换)

1.绝对装入

2.静态重定位

3.动态重定位

绝对装入:在编译时如果知道程序在内存的哪个位置，编译程序将产生绝对地址的目标代码，装入程序按照装入模块的地址，将程序和数据装入内存

只适用于单道程序环境,程序中使用的绝对地址，可在编译或者汇编的时候给出，也可由程序员直接赋予，通常情况下都是编译或汇编时再转换为绝对地址



静态重定位

又叫可重定位装入，编译链接后的地址都是从0开始的，指令中使用的地址，数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行重定位，将逻辑地址变换为物理地址(地址转换是在装入时由装入程序一次完成的)

特点是在一个作业装入程序时，必须分配其要求的全部内存空间，如果没有足够的内存就不能装入该作业。作业一旦进入内存后，在运行期间不能再移动，也不能再申请内存空间



动态重定位

又称动态运行时装入。编译，链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时彩进行。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持

重定位寄存器:存放装入模块的起始位置

允许程序在内存中移动。



链接的三种方式

1.静态链接:在程序运行前先将各目标模块及它们所需的库函数连接成一个完整的可执行文件，之后不再拆开

2.装入时动态链接:将各目标模块装入内存时，边装入边链接的链接方式

3.运行时动态链接:在程序执行中需要该目标模块时才对它进行链接，其优点是便于修改和更新，便于实现对目标模块的共享

### 内存管理

#### 内存空间的分配和回收

内存管理管理什么?操作系统如何记录哪些内存区域已经被分配出去了，哪些还空闲，很多位置可以放置进程，放在哪里?在进程运行结束后如何将进程占用的内存空间回收。

主要分为连续分配管理方式和非连续分配管理方式.

连续分配管理方式又分为了单一连续分配和固定分区分配和动态分区分配

单一连续分配:内存被分成了系统区和用户区，系统区通常位于内存的低地址部分，用于存放操作系统相关数据，用户区用于存放用户进程相关数据。内存只能有一道用户程序，用户程序独占整个用户区空间。优点:实现简单，无外部碎片，可采用覆盖技术扩充内存，不一定需要采用内存保护(用户区只有一个用户进程).缺点:只能用于单用户单任务的操作系统中，由内部碎片，存储器利用率极低。



固定分区分配:将整个用户空间划分成若干固定大小的分区，在每个分区中只装入一道作业，

固定分区分配又分成分区大小相等和分区大小不等的情况，分区大小相等:缺乏灵活性，但是很适用于一台计算机控制多个相同对象的场合(比如钢铁厂由n个相同的炼钢炉，就可以把内存分成n个大小相等的区域存放n个炼钢炉控制程序),分区大小不等:增加了灵活性，可以满足不同大小的进程需求，根据常在系统中运行的作业大小情况进行划分(划分成多个小分区，适量中等分区，少量大分区)

操作系统需要建立一个数据结构:分区说明表，来实现各个分区的分配和回收，每个表项对应一个分区，通常按分区大小排列，每个表项包括对应分区的大小，起始地址，状态(是否已分配)用数组即可表示这个表.当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表，从中找到一个能满足大小的，未分配的分区，将之分配给该程序，然后修改状态为"已分配".

优点:实现简单，无外部碎片

缺点:当用户程序太大时可能所有分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能.会产生内部碎片，内存利用率低



动态分区分配:又叫可变分区分配，不会预先划分内存分区，而是在进程装入内存时根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要，因此系统分区的大小和数目是可变的。

动态分区分配没有内部碎片，但是有外部碎片。内部碎片:分配给某进程的内存区域中，如果有些部分没有用上。

外部碎片:内存中的某些空闲分区由于太小而难以利用.

如果内存中空闲空间的总和本来可以满足某进程的要求，但是由于进程需要的是一整块连续的内存空间，因此这些碎片不能满足进程的需求。可以通过紧凑技术来解决外部碎片

1.系统要用什么样的数据结构记录内存的使用情况?

两种常用的数据结构:空闲分区表，空闲分区链

空闲分区表:每个空闲分区对应一个表项，表项中包含分区号，分区大小，分区起始地址等信息

空闲分区链:每个分区的起始部分和末尾部分分别设置前向指针和后向指针，其实部分处还可记录分区大小等信息



2.当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配?

把一个新作业装入内存时需按照一定的动态分区分配算法从空闲分区表中选出一个分区分配给该作业，由于分配算法对系统性能有很大的映像，因此人们对它进行了广泛的研究



3.如何进行分区的分配和回收操作

#### 内存空间的扩展

操作系统提供某种技术从逻辑上对内存空间进行扩充



#### 地址转换

程序员写程序只需要关注指令数据的逻辑地址，而逻辑地址到物理地址的转换应该由操作系统负责

三种装入方式



####　内存保护

操作系统保证进程在各自的存储空间内运行互不干扰

方法一:在cpu中设置一对上下限寄存器存放进程的上下限地址，进程的指令要访问某个地址时，cpu检查是否越界

方法二:采用重定位寄存器(基址寄存器)和界地址寄存器(又称限长寄存器)进行越界检查。重定位寄存器中存放的是进程的起始物理地址，界地址存放的是进程的最大逻辑地址。



### 覆盖和交换

内存空间的扩充:覆盖技术，交换技术，虚拟存储技术



覆盖技术:把程序分成多个段，常用的段常驻内存，不常用的段在需要时调入内存，内存中分为一个固定区和若干覆盖区,需要的段放在固定区，不常用的段放在覆盖区，需要用到时调入内存，用不到时调出内存

需要程序员声明覆盖结构，操作系统自动完成覆盖，缺点:对用户不透明，增加了用户编程负担



交换技术:内存空间紧张时，系统把内存中某些进程暂时换出外存，把外存中某些已经具备运行条件的进程换入内存(进程在内存和磁盘间动态调度),前面提到的中级调度和这个有关.

应该在外存的什么位置保存被换出的进程?什么时候应该交换?应该换出哪些进程?

1.具有对换功能的操作系统，通常把磁盘空间分为文件区和对换区两部分，文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采取离散分配方式，对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度,因此通常对换区采用连续分配方式，总之对换区的IO速度比文件区的更快，(Linux的swap区)

2.交换通常发生在有许多进程且内存吃紧时进行，而系统符合降低就暂停。例如:在发现许多进程运行时经常发生缺页，说明内存紧张，此时可以换出一些进程，如果缺页率明显下降，就可以暂停换出。

3.可优先考虑换出阻塞进程，可换出优先级低的进程，为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的。



### 动态分区算法

首次适应算法

每次从低地址开始查找，找到第一个能满足大小的空闲分区。

如何实现:空闲分区以地址递增的次序排序，每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区

![image-20221105115229913](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115229913.png)



最佳适应算法

由于动态分区算法是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域，因此为了保证当大进程到来时能有连续的大片空间，可以尽可能多的留下大片空闲区，即优先使用更小的空闲区。

如何实现:空闲分区按容量递增次序链接，每次分配时顺序查找空闲分区链(空闲分区表)，找到大小能满足要求的第一个空闲分区

![image-20221105115206691](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115206691.png)

![image-20221105115341266](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115341266.png)

缺点:每次都选最小的分区进行分配,会留下越来越多的，很小的，难以利用的内存块。因此这种方法会产生很多的外部碎片



最坏适应算法

为了解决最佳适应算法的问题，即留下了太多难以利用的外部碎片，可以在每次分配生时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小方便使用。

如何实现:空闲分区按容量递减次序链接，每次分配顺序查找空闲分区链，找到大小能满足要求的第一个空闲分区。

![image-20221105115848383](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115848383.png)

![image-20221105115900081](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115900081.png)

![image-20221105115915265](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105115915265.png)

缺点:每次都选择最大的分区分配，虽然可以让分配后留下的空闲区更大更可用，但这种分配方式导致较大的连续空闲区被迅速用完，如果之后有大进程到达，就没有内存分区可用了



邻近适应算法

首次适应算法每次都从链头开始查找，这可能导致低地址部分出现很多小的空闲分区，而每次分配查找时都要经过这些分区，因此也增加了查找的开销，如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

如何实现:空闲分区以地址递增的顺序排列(可排成一个循环链表)。每次分配时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区

![image-20221105120721457](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105120721457.png)

![image-20221105120732590](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221105120732590.png)

缺点:首次适应算法每次都要从头查找，每次都需要检索低地址的小分区，但是这种规则也决定了当低地址有更小的分区可以满足要求时，会更有可能用到低地址部分的小分区，也更可能把高地址部分的大分区保留下来(最佳适应算法的优点)



四种算法中，首次适应算法的效果是最好的



### 基本分页存储的基本概念

#### 考虑支持多道程序的两种分配方式:

1.固定分区分配:缺乏灵活性,会产生大量的内部碎片，内存的利用率很低

2.动态分区分配:会产生很多的外部碎片，虽然可以用紧凑技术处理，但是紧凑的时间代价很高

如果允许将一个进程分散的装入许多不相邻的分区中，便可充分地利用内存，而无需再进行紧凑。基于这一思想产生了非连续分配方式，或称为离散分配方式。

非连续分配方式为用户进程分配的可以是一些分散的内存空间，包括基本分页存储管理，基本分段存储管理，段页式存储管理。

#### 把固定分区分配改造为非连续分配版本

解决思路:如果允许进程占用多个分区，那么可以把进程拆分成10MB+10MB+3mb三个部分，再把这三个部分分别放到三个分区中(这些分区不要求连续)，进程的最后一个部分是3MB，放入分区后会产生7MB的内部碎片。如果每个分区大小为2MB，那么进程A可以拆分为11*2MB+1MB共12个碎片，只有最后一部分1MB占不满分区，会产生1MB的内部碎片，如果把分区大小设置得更小一些，那么内部碎片也会更小，内存利用率也会更高，这就是分页存储的思想，把内存分成一个个相等的小分区，再按照分区大小把进程拆分成一个个小部分。

![image-20221107094409331](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221107094409331.png)

#### 分页存储管理的基本思想

把内存空间分成一个个大小相等的分区,每个分区就是一个页框(页帧，内存块，物理块)每个页框都有一个编号(页框号，内存块号，页帧号，物理块号)页框号从0开始，将用户进程的内存空间也分成和页框大小相等的一个个区域，称为页或页面。每个页面也有一个编号，即页号，也是从0开始的。进程的最后一个页面可能没有一个页框那么大，因此页框不能太大，否则可能产生过大的内部碎片。操作系统会以页框为单位为各个进程分配内存空间，进程的每个页面分别放入一个页框中，也就是说进程的页面与内存的页框有一一对应关系。各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中。

#### 如何实现地址的转换

分页后如何实现逻辑地址到物理地址的转换?

1.首先由逻辑地址和页面大小可以直接得到页号和偏移量

逻辑地址/每个页面的大小(每个物理块的大小)=页号

逻辑地址%每个页面的大小(每个物理块的大小)=偏移量offset

在计算机中以二进制的形式表示逻辑地址，每个页面大小为
$$
2^k
$$
则逻辑地址的低k位表示偏移量，(其余位数>>k)表示页号



2.其次，由页号可以得到页框号(物理块号)

页表:一个进程对应一张页表，进程的每一页对应一个页表项，每个页表项由页号和块号组成.记录这进程页面和实际存放的内存块之间的对应关系。

每个页表项的长度是相同的，页号是隐含的，如果知道页表存放的起始地址X和每个页表项的长度(M字节)，那么第M号页对应的页表项一定是存放在内存地址X+3*M.因此页号是不需要显式的表示出来的，只需要知道页表存放的起始位置和页表项长度就可以找到每个页号对应的页表项存放的位置

使用的是动态重定位的装入方式，因此进程被装入内存后仍然用的是逻辑地址，当运行时才会把逻辑地址转换为物理地址。每个进程都在PCB里面保存着页表的起始地址F和页表长度M的信息，当进程转换到运行态时,页表的起始地址F和页表长度M的信息会装入到页表寄存器(PTR)中，这样操作系统通过读取重定位寄存器就可以找到页表，把页号转换为物理块号，物理块号*物理块大小+偏移量=物理地址，这样PC就可以找到下一条指令的位置了!

### 具有快表的地址变换机构

#### 局部性原理

时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行，如果某个数据被访问过，不久后这条数据很可能会再次被访问

空间局部性:一旦程序访问了某个内存单元不久后其临近的存储单元很有可能被访问(因为很多数据在内存中都是连续存放的)

在上小结介绍的基本地址变换机构中，每次要访问一个逻辑地址然后查询内存中的页表，由于局部性原理可能连续很多次查到的都是同一个页表项，既然如此能否利用这个特性减少访问页表的次数呢?

#### 快表

快表，又叫联想寄存器(TLB)，是一种访问速度比内存快的多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程，与此对应的是内存中的页表，叫慢表

![image-20221107101132017](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221107101132017.png)

![image-20221107101205235](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221107101205235.png)

如果在TLB中未命中，则会在内存中的页表中查询，查询后会自动把该页表项拷贝进TLB中，下次查询就无需再在页表中查询了

#### 用快表查询的基本过程

CPU给出逻辑地址，由某个硬取出件算得页号，页内偏移量，将页号与快表(TLB)所有的页号进行比较，如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从该页对应的内存单元的内存块号，再将内存块号与业内偏移量拼接形成物理地址,最后访问该物理地址对应的内存单元，因此若快表命中，则访问某个逻辑地址仅需一次访存即可。。

如果没有找到匹配的页号则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后访问该物理地址对应的内存单元，因此若快表未命中则访问某个逻辑地址需要两次访存(注意，在找到页表项后应将其存入快表，以便后面可能的再次访问，但若快表已满，则需要按照一定的算法对旧的页表项进行替换)

由于查询快表的速度比查询页表的速度快的多，因此只要快表命中，就可以节省很多时间。

### 两级页表

#### 单级页表的问题

问题1.页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。问题2.没有必要让整个页表常驻内存，因为进程在一段时间 内可能只需要访问某几个特定的页面

#### 解决问题

参考之前是如何解决进程在内存中必须连续存储的问题的?将进程地址空间分页，并为其建立一张页表，记录各个页面的存放位置。同样的思路用来解决页表必须存放的问题，把必须连续存放的页表再分页。

我们可以把页表进行分组使每个内存块刚好可以放下一个分组，灵位还要为离散分配的页表再建立一张页表，称为页目录表，或外层页表，或顶层页表。

注意:若采用多级页表机制，则各级页表的大小不能超过一个页面

问题:某系统按字节编址，采用40位逻辑地址，页面大小为4KB,页表项大小为4B，假设采用纯页式存储，则要采用()级页表，页内偏移量为()位

解题:页内偏移量很简单，必须能访问到页面内的每一个地址(以B为单位)则由
$$
2^2*2^10=2^12
$$
至少需要12位

还剩28位，页表项大小为4B,则每个页面可以包含1K(2^10)个页表项

需要10位二进制位才能映射到2^10个页表项，因此每一级的页表对应页号应为10位，总共28位的页号至少要分为3级。



### 分段存储



#### 由逻辑地址得到物理地址的步骤

1、根据逻辑地址得到段号S和段内地址W

2.判断段号是否越界，若S>=M,则产生越界中断，否则继续执行

3.查询段表，找到对应的段表项，段表项给出了段长c和基址b，段表项的存放地址为F+S*段表项长度

4.检查段内地址是否超过段长，若W>=c，则产生越界中断，否则继续执行

5.计算得到物理地址

6.访问目标内存单元

#### 分段分页管理的对比

页是信息的物理单位，分页的主要目的是为了实现离散分配，提高内存利用率，分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。

段是信息的逻辑单位，分段的主要目的是为了更好的满足用户需求，一个段通常包含着一组术语一个逻辑模块的信息。分段对用户是可见的。用户编程时需要显式地给出段名.

![image-20221108194902484](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221108194902484.png)

页的大小固定且由系统决定，段的长度却不固定，决定于用户编写的程序



分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址

分段的用户进程地址空间是二维的，程序员在标记一个地址时既要给出段名，也要给出段内地址。



分段比分页更容易实现信息的共享和保护

不能被修改的代码称为纯代码或可重入代码(不属于临界资源)，这样的代码是可以共享的，可修改的代码是不能共享的(比如有一个代码段中有很多的变量，各进程并发地同时执行可能造成数据不一致)

比如说某个功能段用来判断缓冲区此时是否可以被访问，允许所有生产者，消费者进程共享访问，则只需要让各个进程的段表项指向同一个段即可实现共享。

![image-20221108194216609](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221108194216609.png)



如果让消费者进程的某个页表项指向这个页面显然不合理，因为这个页面中的部分是不允许共享的，只有绿色部分可以

![image-20221108194458553](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221108194458553.png)

分段:第一次访存---查内存中的段表。第二次访存--访问目标内存单元，总共两次访存，与分页系统类似，分段系统中也可以引入快表机制



### 段页式管理方式

#### 分页分段管理方式中最大的优缺点

分页:内存空间利用率高，不会有外部碎片，只有少量的内部碎片，但不方便按照逻辑模块实现信息的共享和保护。

分段管理可以很方便按照逻辑模块实现信息的共享和保护，如果段长过大，为其分配很大的连续空间会很不方便，段式管理会产生外部碎片

#### 分段分页的结合-段页式管理方式

在传统的分段管理的逻辑地址:段号+偏移量的基础上，把偏移量进一步换成页号+偏移量。

#### 段表，页表

#### 如何实现地址转换

由段号找到对应的页表，再由页表找到物理块号，再加上偏移量就是我们要的物理地址了。会三次访存

### 虚拟内存

#### 传统存储管理方式的特征，缺点

一次性:作业必须一次性全部装入内存后后彩能开始运行。这会造成两个问题1.作业很大时不能全部装入内存，导致大作业无法运行2.当大量作业要求运行时由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。驻留性:一旦作业被装入内存，就会一直主流在内存中直到作业运行结束。事实上，在一个时间段内只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的暂时用不到的数据，浪费了宝贵的内存资源。

#### 局部性原理 

1.时间局部性

如果执行了程序中的某条指令，那么不久后这条指令很可能会再次被访问到

2.空间局部性

一旦程序访问了某个存储单元，在不久后其附近的存储单元页很可能被访问(数据在内存中是连续存放的，而且程序的指令而是顺序的在内存中存放的)

3.高速缓存技术

思想是将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放在更低速存储器中

#### 虚拟内存的定义和特征

定义

在程序装入时可以把程序中很快会用到的部分装入内存，暂时用不到的部分留在外存中，就可以执行程序。在程序执行的过程中当所访问的信息不在内存中时由操作系统负责将所需信息从外存调入内存然后继续执行程序。如果内存空间不够由操作系统负责将内存中暂时用不到的信息换出到外存，在操作系统的管理下用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。

区别虚拟内存的最大容量和虚拟内存的实际容量

最大容量是由计算机的CPU寻址能力确定的，实际容量=min(内存和外存之和，CPU寻址范围)



三个特性

多次性:无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存

对换性:在作业运行时无需一直常驻内存，而是允许在作业运行过程中将作业换入换出

虚拟性:从逻辑上扩充了内存的容量使用户的内存容量远大于实际的容量



#### 如何实现虚拟内存技术

建立在离散的存储管理方式的基础上，但在传统的非连续分配存储管理技术(分页，分段，段页式)上还要增加功能:操作系统要提供请求调页(调段)功能，如果需要的页面不在内存中，操作系统负责把页面从外存调入到内存，并且要完善一系列的处理。其次要提供页面置换功能，当内存空间不够时，把用不到的页面或分段换出外存

虚拟内存的实现:请求分页存储管理，请求分段存储管理，请求段页式存储管理



### 请求分页管理方式

请求分页存储管理和基本存储管理的主要区别:

操作系统要提供请求调页功能，将缺失页面从外存调入到内存中在程序执行过程中，当所访问的信息不在内存中，由操作系统负责将所需信息从外存调入到内存中，然后继续执行程序。

操作系统要提供页面置换的功能，将暂时用不到的页面换出到外存，若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。



请求分页管理方式:页表机制，缺页中断机制，地址变换机制。



#### 页表机制:

比起传统的分页机制，请求分页管理方式中的页表项增加了一些其他信息(原来只有内存块号)，现在包括了:

1.内存块号

2.状态位

是否已调入内存

3.访问字段

可记录最近被访问过几次，或记录上次访问的时间，供置换算法选择换出页面时参考。

3.修改位

在内存中是否被修改

4.外存地址

换出到外存后记录下对应的位置

#### 缺页中断机构

访问某个页面时首先查看页表项中的状态位，如果是0会引发缺页中断，控制权交给内核处理这个中断，查看页表项中的外存地址，调用IO将页面从外存中调用到内存中，此时这个进程会被阻塞，等待页面调用到内存中，调页完成后被唤醒放回到就绪队列。



如果内存中有空闲快，则为进程分配一个空闲快，将所缺页面装入到该块，并修改慢表和快表中的页表项。

如果内存中没有空闲快，则由页面置换算法选择一个页面淘汰，先查看页表项中的修改位，如果是1，会引发中断，调用IO设备写回到外存(覆盖外存中的内容)。未修改的页面不用写回到外存



缺页中断是内中断，是因为当前执行的指令想要访问的目标页面未调入内存而产生的。



#### 地址变换机构

![image-20221109155824014](C:\Users\lonux\AppData\Roaming\Typora\typora-user-images\image-20221109155824014.png)

比起传统的分页管理的区别:

新增了三个步骤:

1.请求调页(查到页表项时进行判断)

2.页面置换(需要调入页面，但没有空闲内存块时进行)

3.需要修改请求页表中新增的表项



补充细节:

1.只有写指令才需要修改修改位，而且，一般来说只需要修改快表中的数据，只有要将快表项删除时彩需要写回内存中的慢表，这样可以减少访存次数。

2.和普通的中断处理一样，缺页中断处理依然需要保留CPU现场

3.需要用某个页面置换算法来决定一个换出页面

4.换入换出页面都需要启动慢速的IO操作，可见，如果换入、换出太频繁会有很大的开销。

5.页面调入内存后需要修改慢表，同时也需要将表项复制到快表中

### 页面置换算法

页面的换入换出需要磁盘IO，会有比较大的开销，因此好的页面置换算法应该追求更少的缺页率。

最佳置换算法(OPT),先进先出算法(FIFO),最近最久未使用置换算法(LRU),时钟置换算法（CLOCK），改进型的时钟置换算法。



#### 最佳置换算法(OPT)

这是理论上的，实际上无法实现，因为无法预知未来.

思想是从后往前看(从未来往现在看)，每次淘汰的是以后永远不使用或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。



#### 先进先出算法(FIFO)

谁先进入内存就优先淘汰谁，算法性能很差，因为无法确定先进入内存的页面是否会被频繁使用，这也是唯一一个会发生Belady异常的算法(是指操作系统分配给进程的物理块变多了但缺页次数反而下降的情况，这显然不是我们期望发生的，因为这种不确定性会导致我们无法解决缺页率低的问题)



#### LRU算法

有点意思，有种"以史为鉴,可以知兴替"的感觉，OPT算法从现在往未来看，因为无法预知未来，所以无法实现，而LRU算法是从现在往过去看，用过去的经验对未来进行模拟，虽然需要硬件支持，但这是能做到的，效果最好的算法。

实现方法:赋予每个页面对应的页表项中，用访问字段记录该页面自上次访问以来经历的时间t,当需要淘汰一个页面时，选择现有页面中t值最大的，即最久未使用的页面。

需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大。



#### 时钟置换算法(CLOCK算法)

这是一种性能和开销较均衡的算法

实现方法:

最多两轮扫描:

为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列，当某页被访问时其访问位置是1.当需要淘汰一个页面时，只需要检查页的访问位。如果是0就选择该页换出，如果是1，则将它置0，暂不换出，继续检查下一个页面，若第一轮扫描所有的页面都是1，则将这些页面的访问位依次置0后在进行第二轮扫描，因为第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多经过两轮扫描。



#### 改进的CLOCK算法

简单的CLOCK算法只考虑了一个因素，其实还有一个因素需要被考虑，那就是修改位，我们应该优先考虑置换掉修改位是0的页面，因为不用把这个页面写出到磁盘，少一步IO操作，因此我们用一个(访问位,修改位)记录，有4中可能(0,0),(0,1),(1,0),(1,1)

实现方法:

最多四轮扫描:

为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列，当某页被访问时访问位置1,根据是否被修改把修改位置0或1

第一轮扫描:查看是否有(0,0)的页面,如果有就直接置换这个页面

第二轮扫描:查看是否由(0,1)的页面，如果遇到了(0,1)就置换掉这个页面，否则把访问位的1置0

第三轮扫描:查看是否有(0,0)的页面，如果遇到了就置换这个页面

第四轮扫描:置换掉第一个(0,1)的页面，这是一定会发生的

四轮扫描中只有第二轮扫描会修改flag里面的访问位。



### 页面分配策略

#### 驻留集

操作系统为进程分配的全部内存块的集合

#### 页面分配

操作系统为进程分配物理块的时候有不同的选择，一种是固定分配，一种是可变分配

固定分配是指分配物理块时数目固定，运行期间不再改变。

可变分配是指先为每个进程分配一定数目的物理块，在进程运行时根据情况做出适当的增加或减少，驻留集大小可变



内存紧张时操作系统为进程定义的置换方式又有两种，一种是局部置换，一种是全局置换。

局部置换是指，置换时哪个进程想调页，那么只能选取这个进程自己的页面进行置换。全局置换是指，可以选取任意的不锁定的进程的页面进行调出。



所有的分配方式共有2*2=4种，但是全局置换+固定分配无法实现(全局置换意味着一个进程拥有的物理块数目一定会改变，不可能是局部分配)，所以实际上只有三种分配方式:固定分配局部置换，可变分配全局置换，可变分配局部置换。

##### 固定分配局部置换

系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后调出需要的页面。

这种策略的缺点是很难在刚开始就确定应为每个进程分配多少个物理块才算合理

##### 可变分配全局置换

刚开始会为每个进程分配一定数量的物理块，操作系统会保持一个空闲物理块队列，当某进程发生缺页时从空闲物理块中取出一块分配给该进程，若无空闲物理块，则可以选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。采用这种策略时，只要某进程发生缺页，都能获得新的物理块，仅当空闲物理块用完时系统彩选择一个未锁定的页面调出。

被选择调出的页可能是任意一个进程的页，因此这个被选中的进程拥有的进程拥有的物理块会减少，缺页率增加。

##### 可变分配局部置换

刚开始会为每个进程分配一定数量的物理块，当某进程发生缺页时只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地换页，系统会为该进程多分配几个物理块，直到该进程缺页率趋势适当程度，反之，如果进程在运行时缺页率特别低，则可适当减少分配给该进程的物理块。

可变分配全局置换:只要缺页就分配新物理块

可变分配局部置换:要根据缺页的频率来动态地增加或减少进程的物理块



#### 调入页面的时机

1.预调页策略:根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效，但如果提前调入的页面中大多数都没有访问过，则又是低效的，因此可以预测不久之后可能访问到的页面将它们预先调入内存，但目前预测成功率只有0.5左右，故这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分。

2.请求的呢有策略:进程在运行期间发现缺页时彩将所缺页面调入内存，由这种策略调入的页面一定会被访问到，但由于每次只能调入一页，而每次调页时都要磁盘IO操作，因此IO开销较大。

#### 从何处调页

磁盘分为对换区和文件区，对换区读写速度更快，采用连续分配方式，文件区读写速度更慢，采用离散分配方式

1.系统如果拥有足够的对换空间，页面的调入，调出都是在内存和对换区之间进行，这样可以保证页面的调入，调出的速度很快，在进程运行前需要将进程相关的数据从文件区复制到对换区。

2.系统缺少足够的对换区空间，凡事不会被修改的数据都直接从文件区调入，由于这些数据不会被修改，因此不需要写回磁盘，下次需要时再从文件区调入即可，对于可能被修改的部分，换出时需要写回磁盘对换区，下次需要时再从对换区调入。

3.UNIX方式:运行前的进程相关数据全放在文件区，未使用过的页面都可以从文件区调入，被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。

2和3的区别是，2是不会修改的数据从文件区调入，3是未使用过的页面从文件区调入，其他都从对换区写入。

#### 抖动现象

不好的现象，刚刚换出的页面马上又要换入内存，这种频繁地页面调度行为称为抖动，主要原因是进程频繁访问的页面数大于可用的物理块数(分配给进程的物理块不够)

#### 工作集

在某段时间内进程实际访问页面的集合

滑动窗口:24,15,18,23,24,17,18,24,18,17

24,15,18,23：工作集为24,15,18,23

17,18,24,18:工作集为17,18,24

工作集大小可能小于窗口尺寸，实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块，比如:窗口尺寸为5，经过一段时间后发现某工程的工作集最大为3，那么说明这个进程有很好的局部性，可以分配3个内存块即可满足进程的运行需要

驻留集大小不能小于工作集大小，否则进程运行时会频繁换页。

## 第四章 文件管理	

### 初识文件管理

## 第五章 磁盘管理